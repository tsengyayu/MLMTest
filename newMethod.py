import csv

import polars as pl
import ollama
from tqdm.notebook import tqdm
from transformers import BertTokenizer,AutoTokenizer, AutoModelForSequenceClassification, AutoModel
import spacy
from spacy.util import compile_infix_regex
import torch
import re
import random
from sentence_transformers import SentenceTransformer, util

# 1. å…ˆè§€å¯Ÿèªæ„ç›¸ä¼¼åº¦ï¼Œå†ä¾†æ˜¯labelï¼Œæœ€å¾Œæ˜¯confidence
# ç•¶æœªé€šéæ¨™æº–æ™‚ï¼Œéš¨æ©Ÿé¸æ“‡ä¸€å€‹æƒ…æ„Ÿçµ¦promptï¼Œå˜—è©¦ä¿®æ”¹æ¬¡æ•¸ä¸Šé™å¯ç‚º3ï¼Œ
# 2. å·²ç¶“æ’é™¤åœç”¨è©ã€ä¸»èªã€å°ˆæœ‰åè©ã€ä»£è©ï¼Œå·²ä½¿ç”¨LLMç”ŸæˆåŒç¾©è©
# 3. é€™éƒ¨åˆ†éœ€è¦å†æ€è€ƒemojiè¦åœ¨ä»€éº¼æ™‚å€™ç”Ÿæˆæœƒæ¯”è¼ƒå¥½
# 4. å¥æ³•è§£æå™¨æ˜¯ä»€éº¼è¦çœ‹ä¸€ä¸‹
# 5. æš«æ™‚ä¸è€ƒæ…®äººé¡è©•ä¼°
# 6. æ¨£æœ¬å€‹é¡åˆ¥è¦å¹³è¡¡
# 8. æ˜¯å¦è¦ç”¨è‡ªå‹•åŒ–æç¤ºèª¿æ•´
# å°‡å‰›æ‰å¤±æ•—çš„åŸå› æ”¾é€²å»

modelfile = """
FROM llama3
PARAMETER temperature 0.2
PARAMETER num_ctx 2048
SYSTEM ä½ æ˜¯è³‡æ–™è™•è£¡çš„å·¥å…·ï¼Œä½ åªæœƒç”¨è‹±æ–‡å›è¦†è³‡æ–™å…§å®¹ï¼Œä¸æä¾›å…¶ä»–è³‡è¨Š
"""

##llama 3.2
ollama.create(model='data_processor', modelfile=modelfile)
ollama.list()
tqdm.pandas()

# è¼‰å…¥æ¨¡å‹å’Œ tokenizer
model = AutoModelForSequenceClassification.from_pretrained('./kaggle/working/results/checkpoint-500')
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
embedding_model = AutoModel.from_pretrained("./kaggle/working/results/checkpoint-500")
simility_model = SentenceTransformer('all-MiniLM-L6-v2')

nlp = spacy.load("en_core_web_sm") #åŠ è¼‰NLPæ¨¡å‹

splits = {'train': 'data/train.jsonl', 'validation': 'data/validation.jsonl', 'test': 'data/test.jsonl'}
df_train = pl.read_ndjson('hf://datasets/AdamCodd/emotion-balanced/' + splits['train'])
df_train = df_train.to_pandas()
df_test = pl.read_ndjson('hf://datasets/AdamCodd/emotion-balanced/' + splits['test'])
df_test = df_test.to_pandas()

test_texts = df_test.head(5)['text'].tolist()
test_labels = df_test.head(5)['label'].tolist()

emotion_label = {0:'sadness', 1:'joy', 2:'love', 3:'anger', 4:'fear', 5:'surprise'}

#ç”Ÿæˆæ–°å¥å­
def add_new_sentence(original_sentence, new_label):
    # prompt = f"Based on the following sentence:'{original_sentence}', add a new sentence that naturally flows from the " \
    #          f"original while maintaining the same emotion. When the label is 0, the original sentenceâ€™s " \
    #          f"emotion is negative, and when the label is 1, the emotion is positive. " \
    #          f"The current label is '{original_label}'. Ensure that the added sentence deepens or clarifies the " \
    #          f"expressed emotion and complements the context effectively.The response only includes the final total sentence";

    # prompt = f"Please add a new sentence that has a faint hint of '{new_label}' after the following sentenceï¼š'{original_sentence}' to " \
    #          f"make it slightly more '{new_label}'.but keep the original meaning of the sentence and use only subtle adjustments in tone." \
    #          f"The response only includes the final total sentence.";
    prompt = f"Please add a new sentence that has an emotion that matches the original sentence after the following sentenceï¼š'{original_sentence}'." \
             f"It keep the original meaning of the sentence and use only subtle adjustments in tone." \
             f"The response only includes the final total sentence.";


    data = ollama.generate(model='data_processor', prompt=prompt)

    generated_text = data['response']

    return generated_text

def spacy_tokenize(sentence): # å¥å­æ¨™è¨˜åŒ–è™•ç†ï¼Œåˆ†å‰²æˆä¸€ç³»åˆ—è©èªå’Œæ¨™é»ç¬¦è™Ÿ
    doc = nlp(sentence)
    return ' '.join([token.text for token in doc])

#å¾—åˆ°è©èªé‡è¦æ€§æ’åº1
def get_word_importance(sentence, tokenizer, model):
    # å°‡å¥å­åˆ†è©
    words = sentence.split()
    # å°å®Œæ•´å¥å­é€²è¡Œåˆå§‹é æ¸¬
    original_inputs = tokenizer(sentence, return_tensors="pt", padding=True, truncation=True)
    original_outputs = model(**original_inputs)
    original_prob = torch.softmax(original_outputs.logits, dim=-1).max().item()

    importance_scores = []

    for idx, word in enumerate(words):
        # å°‡è©èªæ›¿æ›ç‚º [MASK] é€²è¡Œå†é æ¸¬
        masked_sentence = ' '.join([w if i != idx else '[MASK]' for i, w in enumerate(words)])
        inputs = tokenizer(masked_sentence, return_tensors="pt", padding=True, truncation=True)
        outputs = model(**inputs)
        new_prob = torch.softmax(outputs.logits, dim=-1).max().item()

        # è¨ˆç®—é‡è¦æ€§ä½œç‚ºæ¦‚ç‡è®ŠåŒ–
        importance = abs(original_prob - new_prob)
        importance_scores.append((word, importance))

    # æŒ‰é‡è¦æ€§é™åºæ’åˆ—è©èª
    importance_scores.sort(key=lambda x: x[1], reverse=True)
    return importance_scores

#å¾—åˆ°è©èªé‡è¦æ€§æ’åº2
def get_word_importance_new(sentence, tokenizer, model, embedding_model):
    # å°‡å¥å­é€²è¡Œåˆ†è©
    words = sentence.split()

    # å°å®Œæ•´å¥å­é€²è¡Œåˆå§‹é æ¸¬
    original_inputs = tokenizer(sentence, return_tensors="pt", padding=True, truncation=True)
    original_outputs = model(**original_inputs)
    original_prob = torch.softmax(original_outputs.logits, dim=-1).max().item()

    # è¨ˆç®—æ•´é«”å¥å­çš„åµŒå…¥è¡¨ç¤º
    with torch.no_grad():
        original_embeddings = embedding_model(**original_inputs).last_hidden_state.mean(dim=1)  # å¹³å‡æ± åŒ–åµŒå…¥

    importance_scores = []

    for idx, word in enumerate(words):
        # é®è”½ç•¶å‰è©èªä¸¦é‡æ–°ç”ŸæˆåµŒå…¥
        masked_sentence = ' '.join([w if i != idx else '[MASK]' for i, w in enumerate(words)])
        inputs = tokenizer(masked_sentence, return_tensors="pt", padding=True, truncation=True)

        with torch.no_grad():
            masked_embeddings = embedding_model(**inputs).last_hidden_state.mean(dim=1)  # å¹³å‡æ± åŒ–åµŒå…¥

        # è¨ˆç®—é®è”½å¾Œçš„åµŒå…¥èˆ‡åŸå§‹åµŒå…¥çš„è·é›¢
        importance = torch.nn.functional.cosine_similarity(original_embeddings, masked_embeddings).item()
        importance_scores.append((word, 1 - importance))  # 1 - cosine similarityä½œç‚ºè·é›¢

    # æŒ‰é‡è¦æ€§é™åºæ’åˆ—è©èª
    importance_scores.sort(key=lambda x: x[1], reverse=True)
    return importance_scores

#è¨ˆç®—è©èªä¹‹é–“çš„è·é›¢
def calculate_distance(word1, word2):
    # ä½¿ç”¨ embedding_model è¨ˆç®—è©èªåµŒå…¥
    inputs1 = tokenizer(word1, return_tensors="pt")
    inputs2 = tokenizer(word2, return_tensors="pt")

    with torch.no_grad():
        embedding1 = embedding_model(**inputs1).last_hidden_state.mean(dim=1)
        embedding2 = embedding_model(**inputs2).last_hidden_state.mean(dim=1)

    # è¨ˆç®—æ­å¼è·é›¢
    distance = torch.dist(embedding1, embedding2).item()
    return distance

#è¨ˆç®—èªæ„ç›¸ä¼¼åº¦
def calculate_simility(original_sentence, modified_sentence, threshold=0.8):
    embedding1 = simility_model.encode(original_sentence, convert_to_tensor=True)
    embedding2 = simility_model.encode(modified_sentence, convert_to_tensor=True)
    similarity = util.pytorch_cos_sim(embedding1, embedding2).item()
    print("similarity: ", similarity)
    return similarity

#è¨ˆç®—åŒç¾©è©èªæ„è·é›¢
def get_distant_synonym(current_text, word,new_label, try_time, problem, distance_threshold=0.8):
    synonyms = get_synonym_from_llama(current_text, word, new_label, try_time, problem)

    # æ‰¾åˆ°èªç¾©è·é›¢æœ€é çš„åŒç¾©è©
    distant_synonym = word
    max_distance = 0

    for synonym in synonyms:
        distance = calculate_distance(word, synonym)

        if distance > max_distance and distance >= distance_threshold:
            max_distance = distance
            distant_synonym = synonym

    return distant_synonym

#ç”ŸæˆåŒç¾©è©
def get_synonym_from_llama(current_text, word, new_label, try_time, problem):
    # prompt = f"Given the following sentence: '{current_text} ', generate a list of replacement words for the word'{word}' in the sentence to confuse the sentiment classification model. The requirements are as follows:" \
    #          f"1. The replacement words should maintain grammatical consistency, especially for pronouns in terms of tense, person, etc." \
    #          f"2. The generated replacements should fit the sentence context and ensure that the sentence remains semantically similar, with natural word order and readability." \
    #          f"3. Focus on replacing descriptive words (e.g., adjectives, adverbs) and avoid changing core nouns or verbs." \
    #          f"4. Where possible, the replacements should confuse the modelâ€™s prediction, but the primary meaning and structure of the sentence should remain intact." \
    #          f"Please generate replacements for each word in the format:'1. replacement 1\n 2. replacement 2\n ... 10. replacement 10\n'.";

    # prompt = f"Please generate a list of replacement words that has a faint hint of '{new_label} ' for the word'{word}'to the following sentenceï¼š['{current_text} '] to " \
    #          f"make it slightly more '{new_label} ', but keep the original meaning of the sentence and use only subtle adjustments in tone." \
    #          f"Please generate replacements for each word in the format:'1. replacement 1\n 2. replacement 2\n ... 10. replacement 10\n'.";
    if(try_time==3):
        prompt = f"Please generate a list of 20 subtle replacement words for '{word}' in the following sentence: '{current_text}'. "\
            f"The replacements should subtly adjust the tone to better align with '{new_label}' while maintaining the sentence's original meaning. "\
            f"Ensure the replacements are natural, contextually appropriate, and not overly strong or extreme. '{problem}' "\
            f"Only provide the list of replacements in this format:\n"\
            f"1. subtle_replacement_1\n2. subtle_replacement_2\n...10. subtle_replacement_10"
        print("new label: ", new_label)
    # prompt = f"Please generate a list of subtle replacement words for '{word}' that adjust the tone of the sentence slightly. "\
    #     f"The replacements should not significantly change the meaning but should introduce a faint hint of a different emotion. "\
    #     f"Make sure the replacements are not overly strong or extreme. Provide 10 alternatives in this format:\n"\
    #     f"1. subtle_replacement_1\n2. subtle_replacement_2\n...10. subtle_replacement_10\n\n"\
    #     f"Context: '{current_text}'."
    if (try_time == 1 or try_time==2):
        # prompt = f"Please generate a list of 20 replacement words for '{word}' in the following sentence: '{current_text}'. " \
        #          f"The replacements should subtly adjust the tone to better align with a different emotion while maintaining the original meaning of the sentence. " \
        #          f"Focus on generating words that are emotionally resonant and contextually appropriate, avoiding overly neutral or unrelated terms. " \
        #          f"{problem}" \
        #          f"Provide the list of replacements in this format:  " \
        #          f"1. replacement_word_1  " \
        #          f"2. replacement_word_2  " \
        #          f"...  " \
        #          f"20. replacement_word_20  "
        prompt = (
            f"Please generate a list of 20 subtle replacement words for '{word}' in the following sentence: '{current_text}'. "
            f"The replacements should slightly adjust the tone, introducing a faint hint of a different emotion while maintaining the sentence's original meaning. "
            f"Ensure the replacements are natural, contextually appropriate, and not overly strong or extreme. '{problem}'"
            f"Only provide the list of replacements in this format:\n"
            f"1. subtle_replacement_1\n2. subtle_replacement_2\n...20. subtle_replacement_20"
        )


    data = ollama.generate(model='data_processor', prompt=prompt)
    # print("prompy: ",prompt)
    generated_text = data['response']
    # print("generated_synonym_from_llama: ", generated_text)
    synonyms = re.findall(r'\d+\.\s(.+)', generated_text)

    return synonyms if synonyms else word

#ç”ŸæˆåŒæ„çŸ­èª
def get_synonym_phrase_from_llama(current_text, word, new_label):
    prompt = f"Please generate a list of replacement phrase that has a faint hint of '{new_label} ' " \
             f"for the word'{word}'to the following sentenceï¼š['{current_text} '] to " \
             f"make it slightly more '{new_label} ', but keep the original meaning of the sentence and use only subtle adjustments in tone." \
             f"Please generate replacements for each word in the format:" \
             f"'1. replacement phrase 1\n 2. replacement phrase 2\n ... 5. replacement phrase 5\n'.";

    data = ollama.generate(model='data_processor', prompt=prompt)

    generated_text = data['response']
    # print("generated_synonym_phrase_from_llama: ", generated_text)
    synonyms = re.findall(r'\d\.\s(.+)', generated_text)


    return synonyms[0] if generated_text else word

#ç”Ÿæˆemoji
def get_emoji_from_llama(sentence, label):
    # prompt = f"Add a kaomoji before or after phrase '{word}' to express emotion." \
    #          f"For example,if original phrase is 'sense a deep-seated anger'. adding emoji, it can become 'ğŸ˜„sense a deep-seated anger(Â°_Â°)'. " \
    #          f"But if original phrase is 'girl'. adding emoji, it can become 'ğŸ˜„girl(Â°_Â°)'" \
    #          f"Please generate kaomoji for phrase and show total in the format:" \
    #          f"'1. replacement phrase 1\n 2. replacement phrase 2\n ... 5. replacement phrase 5.\n'."
    prompt = f"Please select an emoji that reflects a different emotion from the original label and add it to the end of the sentence without disrupting the overall context. " \
             f"Ensure the sentence's meaning remains consistent. Only return the modified sentence (including the chosen emoji).  " \
             f"Below are the sentence and its original label:  " \
             f"Original Label:  '{label}'" \
             f"Sentence:  '{sentence}'"

    data = ollama.generate(model='data_processor', prompt=prompt)

    generated_text = data['response']
    return generated_text
    # print("generated_emoji_from_llama: ", generated_text)
    # synonyms = re.findall(r'\d\.\s([^\n]+)', generated_text)

    # return synonyms[0] if generated_text else word

#æª¢æŸ¥å¥å­èªæ³•æ˜¯å¦æœ‰èª¤
def check_sentence_from_llama(sentence, original_label):
    prompt = f"Check the following sentence for grammatical errors. If there are errors, correct them with the minimal necessary changes " \
             f"to keep the meaning and tone unchanged, while If there is an emoji in the sentence that can move the model's emotion away " \
             f"from the original emotion:'{original_label}', it is retained. Output format just includes changed sentence, only the corrected sentence. " \
             f"If no changes are needed, output the original sentence without any additional text:\n\n{sentence}"
    # prompt = f"Please check the following sentence for grammatical errors and correct them with the minimal necessary changes, ensuring the original meaning and tone are preserved. " \
    #          f"If the sentence contains emojisï¼š " \
    #          f"1. Retain the emoji only if it meaningfully influences the sentence's emotion in a way that moves the emotional tone further away from the original emotion: '{original_label}'." \
    #          f"2. Remove the emoji if it causes the sentence to deviate too far from the original meaning or structure.  " \
    #          f"Output only the corrected sentence. If no changes are needed, output the original sentence without any additional text.  " \
    #          f"Sentence to check: '{sentence}'"

    data = ollama.generate(model='data_processor', prompt=prompt)

    generated_text = data['response']
    return generated_text

#æ¯”è¼ƒåŒç¾©è©å’ŒåŒç¾©çŸ­èªçš„ä¿¡å¿ƒç¨‹åº¦
def compare_word_and_phrase(sentence, word, synonym, synonym_phrase):
    # è¨ˆç®—åŒç¾©è©æ›¿æ›çš„ä¿¡å¿ƒåˆ†æ•¸
    sentence_with_synonym = sentence.replace(word, synonym)
    encoding_synonym = tokenizer(sentence_with_synonym, return_tensors="pt")
    logits_synonym = model(**encoding_synonym).logits
    confidence_synonym = torch.softmax(logits_synonym, dim=-1).max().item()
    # print("1: ",confidence_synonym)

    # è¨ˆç®—åŒç¾©çŸ­èªæ›¿æ›çš„ä¿¡å¿ƒåˆ†æ•¸
    sentence_with_phrase = sentence.replace(word, synonym_phrase)
    encoding_phrase = tokenizer(sentence_with_phrase, return_tensors="pt")
    logits_phrase = model(**encoding_phrase).logits
    confidence_phrase = torch.softmax(logits_phrase, dim=-1).max().item()
    # print("2: ",confidence_phrase)

    # é¸æ“‡ä¿¡å¿ƒåˆ†æ•¸è¼ƒä½çš„æ›¿æ›
    if confidence_synonym < confidence_phrase:
        return synonym
    else:
        return synonym_phrase

#æ›¿æ›å‰10%çš„è©èª
def replace_top_10_percent_words(original_sentence, importance_scores, new_label, try_time, problem):
    importance_scores_sorted = sorted(importance_scores, key=lambda x: x[1], reverse=True)
    num_words_to_replace = max(1, int(0.1 * len(importance_scores_sorted)))
    words_to_replace = [word for word, score in importance_scores[:num_words_to_replace]]
    replaced_sentence = []

    # è§£æåŸå§‹å¥å­ä»¥è­˜åˆ¥äººåã€åœ°åç­‰
    doc = nlp(original_sentence)
    proper_nouns = {ent.text for ent in doc.ents}  # ç²å–äººåã€åœ°åç­‰å‘½åå¯¦é«”
    pronouns = {token.text for token in doc if token.pos_ == "PRON"}  # ç²å–æ‰€æœ‰ä»£è©

    # ä¿ç•™å¥å­ä¸­çš„æ¨™é»ç¬¦è™Ÿï¼Œåˆ†å‰²æˆå–®è©èˆ‡æ¨™é»
    words_with_punctuation = re.findall(r'\w+|[^\w\s]', original_sentence)

    for token in words_with_punctuation:
        word_without_punct = re.sub(r'[^\w]', '', token)

        # æª¢æŸ¥æ˜¯å¦ç‚ºä»£è©æˆ–å‘½åå¯¦é«”ï¼Œä¸æ›¿æ›
        if word_without_punct in words_to_replace and word_without_punct not in proper_nouns and word_without_punct not in pronouns:
            synonym = get_distant_synonym(original_sentence, word_without_punct,new_label, try_time, problem)
            # synonym_phrase = get_synonym_phrase_from_llama(original_sentence, word_without_punct,new_label)
            # match = re.search(r'replacement phrase:\s*(.*)', synonym_phrase, re.IGNORECASE)
            # synonym_phrase_match = match.group(1).strip() if match else synonym
            # synonym_replaced = compare_word_and_phrase(original_sentence, word_without_punct, synonym, synonym_phrase)
            synonym_replaced = synonym
            # print("synonym without emoji: ", synonym_replaced)
            # if(try_time==2 or try_time==3):
            #     synonym_replaced = get_emoji_from_llama(synonym_replaced)
            # print("word_without_punct: ", word_without_punct)
            # print("synonym: ", synonym)
            # print("synonym_phrase: ", synonym_phrase)
            # print("synonym: ", synonym_replaced)
            replaced_token = token.replace(word_without_punct, synonym_replaced)
            replaced_sentence.append(replaced_token)
            # break;
        else:
            replaced_sentence.append(token)

    return ' '.join(replaced_sentence)

adversarial_samples = []
output_csv = "adversarial_samples.csv"


for i, (original_sentence, original_label) in enumerate(zip(test_texts, test_labels)):
    print(f"\nProcessing Sentence {i + 1}...")
    print("original sentence: ", original_sentence)
    # å‰µå»ºæ’é™¤åŸå§‹æ¨™ç±¤çš„æ¨™ç±¤æ¸…å–®
    new_labels = [label for label in emotion_label if label != original_label]
    # éš¨æ©Ÿé¸æ“‡ä¸€å€‹æ–°çš„æ¨™ç±¤
    new_label = emotion_label[random.choice(new_labels)]
    #ç”Ÿæˆæ–°å¥å­
    original_sentence = add_new_sentence(original_sentence, new_label)
    print("add_original sentence: ", original_sentence)

    #æ–·å¥
    # åœç”¨æœƒå°è‡´ç¸®å¯«è©åˆ†é–‹çš„ infix æ¨¡å¼
    infix_re = compile_infix_regex(nlp.Defaults.infixes)
    infix_patterns = [pattern for pattern in infix_re.pattern.split("|") if "'" not in pattern]
    nlp.tokenizer.infix_finditer = compile_infix_regex(infix_patterns).finditer
    processed_sentence = spacy_tokenize(original_sentence)

    problem = ""

    for try_time in range(1, 4):
        # è¨ˆç®—è©èªé‡è¦æ€§
        #æ–¹æ³•ä¸€
        original_sentence_importance = get_word_importance(processed_sentence, tokenizer, model)
        # print("original_importance_scores", original_sentence_importance)
        #æ–¹æ³•äºŒï¼šåµŒå…¥æ³•
        # original_sentence_importance = get_word_importance_new(processed_sentence, tokenizer, model, embedding_model)
        # print("original_importance_scores", original_sentence_importance)

        # ç”ŸæˆåŒç¾©è©æ›¿æ›å¥å­
        new_sentence = replace_top_10_percent_words(original_sentence, original_sentence_importance, new_label, try_time, problem)
        if (try_time == 2 or try_time == 3):
            new_sentence = get_emoji_from_llama(new_sentence, emotion_label[original_label])
        new_sentence = check_sentence_from_llama(new_sentence, emotion_label[original_label])
        print("checked sentence: ", new_sentence)
        similarity = calculate_simility(original_sentence, new_sentence)

    #æ¸¬è©¦
        # new_sentence = "I feel overjoyed to see so many people participating! Itâ€™s wonderful to witness this celebration of art and culture, and the energy is so uplifting."
        # # å°‡æ¸¬è©¦å¥å­é€²è¡Œ tokenization
        test_encodings = tokenizer(new_sentence, truncation=True, padding=True, return_tensors="pt")

        # å°‡æ¸¬è©¦æ•¸æ“šå‚³å…¥æ¨¡å‹ï¼Œé€²è¡Œé æ¸¬
        outputs = model(**test_encodings)

        # å–å¾—é æ¸¬çš„æ¨™ç±¤ (logits æ˜¯æ¨¡å‹çš„è¼¸å‡º)
        logits = outputs.logits
        predictions = logits.argmax(dim=-1)
        # è¨ˆç®—ä¿¡å¿ƒåˆ†æ•¸
        confidence = torch.softmax(logits, dim=-1).max().item()
        print(f"Predicted Confidence Scores: {confidence}")

        # è½‰æ›ç‚ºå¯è®€çš„æ¨™ç±¤
        print("original labels:", original_label)
        print("Predicted labels:", predictions.item())
        if(similarity > 0.8 and (predictions.item() != original_label or confidence <= 0.6)):
            print("Success! try time: ", try_time)
            adversarial_samples.append({
                "original_sentence": original_sentence,
                "original_label": original_label,
                "new_sentence": new_sentence,
                "new_label": predictions.item()
            })
            break
        #æ·»åŠ å•é¡Œåˆ°prompt
        if(similarity < 0.8):
            problem = "The previously generated sentence failed semantic similarity checks (similarity: "+str(similarity)+"). " \
                      "Example of a failed sentence: ã€Œ"+new_sentence+"ã€. Avoid using words from the failed sentence and regenerate " \
                      "replacements based on the original sentence. "
        elif(predictions.item() == original_label or confidence > 0.7):
            problem = "The sentence labels generated in the previous round did not change. Example of a failed sentence: ã€Œ"+new_sentence+"ã€. " \
                      "This time, the generated words should be more effective in shifting the emotional tone or direction while keeping the " \
                      "sentence natural and contextually appropriate. "

with open(output_csv, mode="w", newline="", encoding="utf-8") as file:
    writer = csv.DictWriter(file, fieldnames=["original_sentence", "original_label", "new_sentence", "new_label"])
    writer.writeheader()
    writer.writerows(adversarial_samples)

print(f"Adversarial samples saved to {output_csv}")

    # # prompt = f'Please add a faint hint of worry to the following sentenceï¼š'+new_sentence+' to make it slightly more fearful, and replace all the emotion words in the sentence with other words, but keep the original meaning of the sentence and use only subtle adjustments in tone.';
    # prompt = f'Please add a faint hint of '+emotion_label[new_label]+' to the following sentenceï¼š['+new_sentence+'] to make it slightly more '+emotion_label[new_label]+',and replace all the emotion words in the sentence with other words, but keep the original meaning of the sentence and use only subtle adjustments in tone.'
    # data = ollama.generate(model='data_processor', prompt=prompt)
    # print("prompt: ", prompt)
    # generated_text = data['response']
    # print("generated_text_from_llama: ", generated_text)
    #
    # # å°‡æ¸¬è©¦å¥å­é€²è¡Œ tokenization
    # test_encodings = tokenizer(generated_text, truncation=True, padding=True, return_tensors="pt")
    #
    # # å°‡æ¸¬è©¦æ•¸æ“šå‚³å…¥æ¨¡å‹ï¼Œé€²è¡Œé æ¸¬
    # outputs = model(**test_encodings)
    #
    # # å–å¾—é æ¸¬çš„æ¨™ç±¤ (logits æ˜¯æ¨¡å‹çš„è¼¸å‡º)
    # logits = outputs.logits
    # predictions = logits.argmax(dim=-1)
    #
    # # è¨ˆç®—ä¿¡å¿ƒåˆ†æ•¸
    # confidence = torch.softmax(logits, dim=-1).max().item()
    # print(f"Predicted Confidence Scores: {confidence}")
    #
    # print("Predicted labels:", predictions.item())

# æ˜¯å¦éœ€è¦æŠŠå•é¡Œæ”¾é€²promptä¸­!!
# è¦æŠŠæª¢æŸ¥å¾Œå¯èƒ½æœƒå‡ºç¾çš„å¤šé¤˜å…§å®¹å»æ‰
# 1.æ­£å¸¸ 2.å¢åŠ emoji 3.å¢åŠ éš¨æ©Ÿlabel ï¼Ÿèªæ„ç›¸ä¼¼åº¦å¤ªä½çš„è§£æ±ºæ–¹æ³•ï¼Ÿ
# ä¸€æ¬¡æ€§é€²è¡Œéå¤šçš„ä¿®æ”¹å¯èƒ½å°è‡´èªæ„æå¤±